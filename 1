INFO 02-06 19:34:37 [__init__.py:36] Available plugins for group vllm.platform_plugins:
INFO 02-06 19:34:37 [__init__.py:38] - ascend -> vllm_ascend:register
INFO 02-06 19:34:37 [__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 02-06 19:34:37 [__init__.py:207] Platform plugin ascend is activated
[2026-02-06 19:34:41.029315][UC][I] Logger initialized successfully [10897,10897][__init__.py:48,<module>]
WARNING 02-06 19:34:41 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
[2026-02-06 19:34:41.065437][UC][I] vLLM 0.11.0 patches applied successfully [10897,10897][vllm_patch.py:38,_apply_vllm_patches]
[2026-02-06 19:34:41.066470][UC][I] All vLLM patches applied successfully for version 0.11.0 [10897,10897][apply_patch.py:149,apply_all_patches]
WARNING 02-06 19:34:41 [registry.py:582] Model architecture Qwen2VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_vl:AscendQwen2VLForConditionalGeneration.
WARNING 02-06 19:34:41 [registry.py:582] Model architecture Qwen3VLMoeForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl_without_padding:AscendQwen3VLMoeForConditionalGeneration.
WARNING 02-06 19:34:41 [registry.py:582] Model architecture Qwen3VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl_without_padding:AscendQwen3VLForConditionalGeneration.
WARNING 02-06 19:34:41 [registry.py:582] Model architecture Qwen2_5_VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl:AscendQwen2_5_VLForConditionalGeneration.
WARNING 02-06 19:34:41 [registry.py:582] Model architecture Qwen2_5OmniModel is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_omni_thinker:AscendQwen2_5OmniThinkerForConditionalGeneration.
WARNING 02-06 19:34:41 [registry.py:582] Model architecture DeepseekV32ForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.deepseek_v3_2:CustomDeepseekV3ForCausalLM.
WARNING 02-06 19:34:41 [registry.py:582] Model architecture Qwen3NextForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen3_next:CustomQwen3NextForCausalLM.
INFO 02-06 19:34:41 [utils.py:233] non-default args: {'trust_remote_code': True, 'max_model_len': 32768, 'distributed_executor_backend': 'mp', 'tensor_parallel_size': 4, 'block_size': 128, 'gpu_memory_utilization': 0.8, 'enforce_eager': True, 'kv_transfer_config': KVTransferConfig(kv_connector='UCMConnector', engine_id='15c3696a-82e8-4096-b3c9-58c78b029d4c', kv_buffer_device='cuda', kv_buffer_size=1000000000.0, kv_role='kv_both', kv_rank=None, kv_parallel_size=1, kv_ip='127.0.0.1', kv_port=14579, kv_connector_extra_config={'UCM_CONFIG_FILE': 'ucm_config_example.yaml'}, kv_connector_module_path='ucm.integration.vllm.ucm_connector'), 'model': '/docker/models/DeepSeek-V2-Lite-Chat'}
INFO 02-06 19:34:41 [importing.py:63] Triton not installed or not compatible; certain GPU-related functions will not be available.
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
INFO 02-06 19:34:41 [config.py:388] Replacing legacy 'type' key with 'rope_type'
INFO 02-06 19:34:42 [model.py:547] Resolved architecture: DeepseekV2ForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 02-06 19:34:42 [model.py:1510] Using max model len 32768
INFO 02-06 19:34:42 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 02-06 19:34:42 [__init__.py:381] Cudagraph is disabled under eager mode
INFO 02-06 19:34:42 [platform.py:151] Compilation disabled, using eager mode by default
WARNING 02-06 19:34:42 [platform.py:270] If chunked prefill or prefix caching is enabled, block size must be set to 128.
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:42 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:42 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/docker/models/DeepSeek-V2-Lite-Chat', speculative_config=None, tokenizer='/docker/models/DeepSeek-V2-Lite-Chat', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=npu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/docker/models/DeepSeek-V2-Lite-Chat, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":["all"],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP0 pid=11037)[0;0m WARNING 02-06 19:34:42 [multiproc_executor.py:720] Reducing Torch parallelism from 192 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:42 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 16777216, 10, 'psm_511bc1f0'), local_subscribe_addr='ipc:///tmp/2a25f336-83c9-4ca2-bb90-0cdc73f173b5', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:45 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_3469ce18'), local_subscribe_addr='ipc:///tmp/57461e0c-6485-4c1f-8f01-11c17cecc835', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:45 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_492521a5'), local_subscribe_addr='ipc:///tmp/310deac0-5dec-4c70-a4bf-f41887ac220a', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:45 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_0383589a'), local_subscribe_addr='ipc:///tmp/d38d2372-d523-4f94-9d44-da75f2729055', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:45 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_d71b18a2'), local_subscribe_addr='ipc:///tmp/90b51af2-d40a-49cf-8112-3fc37af51f0c', remote_subscribe_addr=None, remote_addr_ipv6=False)
[rank3]:[W206 19:34:45.513995660 ProcessGroupGloo.cpp:727] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())
[rank2]:[W206 19:34:45.628721985 ProcessGroupGloo.cpp:727] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())
[rank1]:[W206 19:34:45.907404379 ProcessGroupGloo.cpp:727] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())
[rank0]:[W206 19:34:45.918381107 ProcessGroupGloo.cpp:727] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:45 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_1329b522'), local_subscribe_addr='ipc:///tmp/74802500-6c94-4440-bd9f-befb29a97a39', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:46 [parallel_state.py:1208] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:46 [parallel_state.py:1208] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:46 [parallel_state.py:1208] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2, EP rank 2
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:46 [parallel_state.py:1208] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3, EP rank 3
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:46 [factory.py:51] Creating v1 connector with name: UCMConnector and engine_id: 15c3696a-82e8-4096-b3c9-58c78b029d4c
[1;36m(EngineCore_DP0 pid=11037)[0;0m WARNING 02-06 19:34:46 [base.py:86] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
[1;36m(EngineCore_DP0 pid=11037)[0;0m WARNING 02-06 19:34:46 [base.py:86] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
[2026-02-06 19:34:46.076686][UC][I] NPU device is available. [11052,10897][ucm_connector.py:110,__init__]
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:46 [factory.py:51] Creating v1 connector with name: UCMConnector and engine_id: 15c3696a-82e8-4096-b3c9-58c78b029d4c
[1;36m(EngineCore_DP0 pid=11037)[0;0m WARNING 02-06 19:34:46 [base.py:86] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
[1;36m(EngineCore_DP0 pid=11037)[0;0m WARNING 02-06 19:34:46 [base.py:86] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
[2026-02-06 19:34:46.079472][UC][I] NPU device is available. [11057,10897][ucm_connector.py:110,__init__]
[2026-02-06 19:34:46.080104][UC][I] Loaded UCM config from ucm_config_example.yaml [11052,10897][utils.py:54,load_ucm_config_from_yaml]
[2026-02-06 19:34:46.080190][UC][I] Using UCM with config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11052,10897][utils.py:89,get_config]
[2026-02-06 19:34:46.080387][UC][I] self.launch_config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11052,10897][ucm_connector.py:128,__init__]
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:46 [factory.py:51] Creating v1 connector with name: UCMConnector and engine_id: 15c3696a-82e8-4096-b3c9-58c78b029d4c
[1;36m(EngineCore_DP0 pid=11037)[0;0m WARNING 02-06 19:34:46 [base.py:86] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
[1;36m(EngineCore_DP0 pid=11037)[0;0m WARNING 02-06 19:34:46 [base.py:86] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
[2026-02-06 19:34:46.081535][UC][I] NPU device is available. [11047,10897][ucm_connector.py:110,__init__]
[2026-02-06 19:34:46.082585][UC][I] Loaded UCM config from ucm_config_example.yaml [11052,10897][utils.py:54,load_ucm_config_from_yaml]
[2026-02-06 19:34:46.082661][UC][I] Using UCM with config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11052,10897][utils.py:89,get_config]
[2026-02-06 19:34:46.082844][UC][I] Initializing UCM sparse agent with method: {'GSAOnDevice': {}} [11052,10897][state.py:50,ensure_ucm_sparse_initialized]
[2026-02-06 19:34:46.083481][UC][I] Loaded UCM config from ucm_config_example.yaml [11057,10897][utils.py:54,load_ucm_config_from_yaml]
[2026-02-06 19:34:46.083578][UC][I] Using UCM with config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11057,10897][utils.py:89,get_config]
[2026-02-06 19:34:46.083731][UC][I] self.launch_config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11057,10897][ucm_connector.py:128,__init__]
[2026-02-06 19:34:46.085011][UC][I] Loaded UCM config from ucm_config_example.yaml [11052,10897][utils.py:54,load_ucm_config_from_yaml]
[2026-02-06 19:34:46.085076][UC][I] Using UCM with config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11052,10897][utils.py:89,get_config]
[1;36m(EngineCore_DP0 pid=11037)[0;0m INFO 02-06 19:34:46 [factory.py:51] Creating v1 connector with name: UCMConnector and engine_id: 15c3696a-82e8-4096-b3c9-58c78b029d4c
[1;36m(EngineCore_DP0 pid=11037)[0;0m WARNING 02-06 19:34:46 [base.py:86] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
[2026-02-06 19:34:46.086354][UC][I] Loaded UCM config from ucm_config_example.yaml [11057,10897][utils.py:54,load_ucm_config_from_yaml]
[2026-02-06 19:34:46.086474][UC][I] Loaded UCM config from ucm_config_example.yaml [11047,10897][utils.py:54,load_ucm_config_from_yaml]
[2026-02-06 19:34:46.086487][UC][I] Using UCM with config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11057,10897][utils.py:89,get_config]
[1;36m(EngineCore_DP0 pid=11037)[0;0m WARNING 02-06 19:34:46 [base.py:86] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
[2026-02-06 19:34:46.086567][UC][I] Initializing UCM sparse agent with method: {'GSAOnDevice': {}} [11057,10897][state.py:50,ensure_ucm_sparse_initialized]
[2026-02-06 19:34:46.086772][UC][I] Using UCM with config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11047,10897][utils.py:89,get_config]
[2026-02-06 19:34:46.086835][UC][I] self.launch_config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11047,10897][ucm_connector.py:128,__init__]
[2026-02-06 19:34:46.087419][UC][I] NPU device is available. [11044,10897][ucm_connector.py:110,__init__]
[2026-02-06 19:34:46.089021][UC][I] Loaded UCM config from ucm_config_example.yaml [11057,10897][utils.py:54,load_ucm_config_from_yaml]
[2026-02-06 19:34:46.089096][UC][I] Using UCM with config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11057,10897][utils.py:89,get_config]
[2026-02-06 19:34:46.089401][UC][I] Loaded UCM config from ucm_config_example.yaml [11047,10897][utils.py:54,load_ucm_config_from_yaml]
[2026-02-06 19:34:46.089733][UC][I] Using UCM with config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11047,10897][utils.py:89,get_config]
[2026-02-06 19:34:46.089859][UC][I] Initializing UCM sparse agent with method: {'GSAOnDevice': {}} [11047,10897][state.py:50,ensure_ucm_sparse_initialized]
[2026-02-06 19:34:46.092571][UC][I] Loaded UCM config from ucm_config_example.yaml [11047,10897][utils.py:54,load_ucm_config_from_yaml]
[2026-02-06 19:34:46.092653][UC][I] Using UCM with config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11047,10897][utils.py:89,get_config]
[2026-02-06 19:34:46.093330][UC][I] Loaded UCM config from ucm_config_example.yaml [11044,10897][utils.py:54,load_ucm_config_from_yaml]
[2026-02-06 19:34:46.093455][UC][I] Using UCM with config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11044,10897][utils.py:89,get_config]
[2026-02-06 19:34:46.093654][UC][I] self.launch_config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11044,10897][ucm_connector.py:128,__init__]
[2026-02-06 19:34:46.096050][UC][I] Loaded UCM config from ucm_config_example.yaml [11044,10897][utils.py:54,load_ucm_config_from_yaml]
[2026-02-06 19:34:46.096130][UC][I] Using UCM with config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11044,10897][utils.py:89,get_config]
[2026-02-06 19:34:46.096361][UC][I] Initializing UCM sparse agent with method: {'GSAOnDevice': {}} [11044,10897][state.py:50,ensure_ucm_sparse_initialized]
[2026-02-06 19:34:46.098586][UC][I] Loaded UCM config from ucm_config_example.yaml [11044,10897][utils.py:54,load_ucm_config_from_yaml]
[2026-02-06 19:34:46.098662][UC][I] Using UCM with config: {'ucm_connectors': [{'ucm_connector_name': 'UcmNfsStore', 'ucm_connector_config': {'storage_backends': '/docker/ldeng/kv_cache', 'io_direct': False}}], 'ucm_sparse_config': {'GSAOnDevice': {}}} [11044,10897][utils.py:89,get_config]
[2026-02-06 19:34:46.159171][UC][I] Creating sparse method with name: GSAOnDevice [11052,10897][factory.py:43,create_sparse_method]
[2026-02-06 19:34:46.159414][UC][I] [GSAOnDevice] model name: /docker/models/deepseek-v2-lite-chat [11052,10897][gsa_on_device.py:48,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.159580][UC][I] [GSAOnDevice] target relative path: ucm/sparse/gsa_on_device/configs/gsa_on_device_deepseek_v2_lite_config.json [11052,10897][gsa_on_device.py:67,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.160357][UC][I] [GSAOnDevice] repo root detected at depth=4: /docker/ldeng/ucm/unified-cache-management [11052,10897][gsa_on_device.py:79,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.160729][UC][I] [GSAOnDevice] config loaded from SOURCE tree: /docker/ldeng/ucm/unified-cache-management/ucm/sparse/gsa_on_device/configs/gsa_on_device_deepseek_v2_lite_config.json [11052,10897][gsa_on_device.py:81,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.161318][UC][I] read gsa_on_device config file : /docker/ldeng/ucm/unified-cache-management/ucm/sparse/gsa_on_device/configs/gsa_on_device_deepseek_v2_lite_config.json  [11052,10897][gsa_on_device.py:131,__init__]
[2026-02-06 19:34:46.161478][UC][I] GSAOnDevice initialized with MLA model config [11052,10897][gsa_on_device.py:190,__init__]
[2026-02-06 19:34:46.161701][UC][W] NPU only supports float16, float32 and float64 for hash_weights [11052,10897][hash_encoder.py:302,__init__]
[2026-02-06 19:34:46.161724][UC][W] automatically using  float16 for hash_weights now [11052,10897][hash_encoder.py:305,__init__]
[2026-02-06 19:34:46.173225][UC][I] Creating sparse method with name: GSAOnDevice [11047,10897][factory.py:43,create_sparse_method]
[2026-02-06 19:34:46.173424][UC][I] [GSAOnDevice] model name: /docker/models/deepseek-v2-lite-chat [11047,10897][gsa_on_device.py:48,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.173563][UC][I] [GSAOnDevice] target relative path: ucm/sparse/gsa_on_device/configs/gsa_on_device_deepseek_v2_lite_config.json [11047,10897][gsa_on_device.py:67,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.174176][UC][I] [GSAOnDevice] repo root detected at depth=4: /docker/ldeng/ucm/unified-cache-management [11047,10897][gsa_on_device.py:79,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.174238][UC][I] [GSAOnDevice] config loaded from SOURCE tree: /docker/ldeng/ucm/unified-cache-management/ucm/sparse/gsa_on_device/configs/gsa_on_device_deepseek_v2_lite_config.json [11047,10897][gsa_on_device.py:81,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.174683][UC][I] read gsa_on_device config file : /docker/ldeng/ucm/unified-cache-management/ucm/sparse/gsa_on_device/configs/gsa_on_device_deepseek_v2_lite_config.json  [11047,10897][gsa_on_device.py:131,__init__]
[2026-02-06 19:34:46.174815][UC][I] GSAOnDevice initialized with MLA model config [11047,10897][gsa_on_device.py:190,__init__]
[2026-02-06 19:34:46.175069][UC][W] NPU only supports float16, float32 and float64 for hash_weights [11047,10897][hash_encoder.py:302,__init__]
[2026-02-06 19:34:46.175094][UC][W] automatically using  float16 for hash_weights now [11047,10897][hash_encoder.py:305,__init__]
[2026-02-06 19:34:46.181414][UC][I] Creating sparse method with name: GSAOnDevice [11057,10897][factory.py:43,create_sparse_method]
[2026-02-06 19:34:46.181654][UC][I] [GSAOnDevice] model name: /docker/models/deepseek-v2-lite-chat [11057,10897][gsa_on_device.py:48,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.181774][UC][I] [GSAOnDevice] target relative path: ucm/sparse/gsa_on_device/configs/gsa_on_device_deepseek_v2_lite_config.json [11057,10897][gsa_on_device.py:67,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.182441][UC][I] [GSAOnDevice] repo root detected at depth=4: /docker/ldeng/ucm/unified-cache-management [11057,10897][gsa_on_device.py:79,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.182505][UC][I] [GSAOnDevice] config loaded from SOURCE tree: /docker/ldeng/ucm/unified-cache-management/ucm/sparse/gsa_on_device/configs/gsa_on_device_deepseek_v2_lite_config.json [11057,10897][gsa_on_device.py:81,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.182995][UC][I] read gsa_on_device config file : /docker/ldeng/ucm/unified-cache-management/ucm/sparse/gsa_on_device/configs/gsa_on_device_deepseek_v2_lite_config.json  [11057,10897][gsa_on_device.py:131,__init__]
[2026-02-06 19:34:46.183127][UC][I] GSAOnDevice initialized with MLA model config [11057,10897][gsa_on_device.py:190,__init__]
[2026-02-06 19:34:46.183378][UC][W] NPU only supports float16, float32 and float64 for hash_weights [11057,10897][hash_encoder.py:302,__init__]
[2026-02-06 19:34:46.183404][UC][W] automatically using  float16 for hash_weights now [11057,10897][hash_encoder.py:305,__init__]
[2026-02-06 19:34:46.199773][UC][I] Creating sparse method with name: GSAOnDevice [11044,10897][factory.py:43,create_sparse_method]
[2026-02-06 19:34:46.200095][UC][I] [GSAOnDevice] model name: /docker/models/deepseek-v2-lite-chat [11044,10897][gsa_on_device.py:48,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.200136][UC][I] [GSAOnDevice] target relative path: ucm/sparse/gsa_on_device/configs/gsa_on_device_deepseek_v2_lite_config.json [11044,10897][gsa_on_device.py:67,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.200960][UC][I] [GSAOnDevice] repo root detected at depth=4: /docker/ldeng/ucm/unified-cache-management [11044,10897][gsa_on_device.py:79,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.201031][UC][I] [GSAOnDevice] config loaded from SOURCE tree: /docker/ldeng/ucm/unified-cache-management/ucm/sparse/gsa_on_device/configs/gsa_on_device_deepseek_v2_lite_config.json [11044,10897][gsa_on_device.py:81,gsa_on_device_config_path_for_model]
[2026-02-06 19:34:46.201569][UC][I] read gsa_on_device config file : /docker/ldeng/ucm/unified-cache-management/ucm/sparse/gsa_on_device/configs/gsa_on_device_deepseek_v2_lite_config.json  [11044,10897][gsa_on_device.py:131,__init__]
[2026-02-06 19:34:46.201735][UC][I] GSAOnDevice initialized with MLA model config [11044,10897][gsa_on_device.py:190,__init__]
[2026-02-06 19:34:46.201899][UC][W] NPU only supports float16, float32 and float64 for hash_weights [11044,10897][hash_encoder.py:302,__init__]
[2026-02-06 19:34:46.201924][UC][W] automatically using  float16 for hash_weights now [11044,10897][hash_encoder.py:305,__init__]
[2026-02-06 19:34:46.377699][UC][W] NPU only supports float16, float32 and float64 for hash_weights [11052,10897][hash_encoder.py:302,__init__]
[2026-02-06 19:34:46.377782][UC][W] automatically using  float16 for hash_weights now [11052,10897][hash_encoder.py:305,__init__]
[2026-02-06 19:34:46.392218][UC][W] NPU only supports float16, float32 and float64 for hash_weights [11047,10897][hash_encoder.py:302,__init__]
[2026-02-06 19:34:46.392296][UC][W] automatically using  float16 for hash_weights now [11047,10897][hash_encoder.py:305,__init__]
[2026-02-06 19:34:46.404211][UC][W] NPU only supports float16, float32 and float64 for hash_weights [11057,10897][hash_encoder.py:302,__init__]
[2026-02-06 19:34:46.404284][UC][W] automatically using  float16 for hash_weights now [11057,10897][hash_encoder.py:305,__init__]
[2026-02-06 19:34:46.410442][UC][W] NPU only supports float16, float32 and float64 for hash_weights [11044,10897][hash_encoder.py:302,__init__]
[2026-02-06 19:34:46.410534][UC][W] automatically using  float16 for hash_weights now [11044,10897][hash_encoder.py:305,__init__]
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m INFO 02-06 19:34:46 [model_runner_v1.py:2702] Starting to load model /docker/models/DeepSeek-V2-Lite-Chat...
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m INFO 02-06 19:34:46 [model_runner_v1.py:2702] Starting to load model /docker/models/DeepSeek-V2-Lite-Chat...
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m INFO 02-06 19:34:46 [model_runner_v1.py:2702] Starting to load model /docker/models/DeepSeek-V2-Lite-Chat...
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m INFO 02-06 19:34:46 [model_runner_v1.py:2702] Starting to load model /docker/models/DeepSeek-V2-Lite-Chat...
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.30s/it]
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:03<00:03,  1.81s/it]
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m INFO 02-06 19:34:55 [default_loader.py:267] Loading weights took 4.91 seconds
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m INFO 02-06 19:34:55 [default_loader.py:267] Loading weights took 4.92 seconds
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:05<00:01,  1.89s/it]
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m INFO 02-06 19:34:55 [default_loader.py:267] Loading weights took 5.32 seconds
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:07<00:00,  1.99s/it]
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:07<00:00,  1.90s/it]
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m 
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m INFO 02-06 19:34:58 [default_loader.py:267] Loading weights took 7.92 seconds
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m WARNING 02-06 19:35:01 [mla_v1.py:698] Currently mlapo only supports W8A8 quantization in MLA scenario.Some layers in your model are not quantized with W8A8,thus mlapo is disabled for these layers.
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m WARNING 02-06 19:35:01 [mla_v1.py:698] Currently mlapo only supports W8A8 quantization in MLA scenario.Some layers in your model are not quantized with W8A8,thus mlapo is disabled for these layers.
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m WARNING 02-06 19:35:02 [mla_v1.py:698] Currently mlapo only supports W8A8 quantization in MLA scenario.Some layers in your model are not quantized with W8A8,thus mlapo is disabled for these layers.
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m INFO 02-06 19:35:03 [model_runner_v1.py:2728] Loading model weights took 7.4781 GB
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m INFO 02-06 19:35:03 [model_runner_v1.py:2728] Loading model weights took 7.4781 GB
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m INFO 02-06 19:35:03 [model_runner_v1.py:2728] Loading model weights took 7.4781 GB
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m WARNING 02-06 19:35:04 [mla_v1.py:698] Currently mlapo only supports W8A8 quantization in MLA scenario.Some layers in your model are not quantized with W8A8,thus mlapo is disabled for these layers.
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m INFO 02-06 19:35:06 [model_runner_v1.py:2728] Loading model weights took 7.4781 GB
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m WARNING 02-06 19:35:06 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m WARNING 02-06 19:35:06 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m WARNING 02-06 19:35:06 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m WARNING 02-06 19:35:08 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
rm: cannot remove '/docker/ldeng/vllm-scripts/kernel_meta/kernel_meta_temp_10237792841344343664': Directory not empty
rm: cannot remove '/docker/ldeng/vllm-scripts/kernel_meta/kernel_meta_temp_2015716319841912157': Directory not empty
rm: cannot remove '/docker/ldeng/vllm-scripts/kernel_meta/kernel_meta_temp_17411788043193864782'rm: cannot remove '/docker/ldeng/vllm-scripts/kernel_meta/kernel_meta_temp_9370168900107203856': Directory not empty: Directory not empty

[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m Exception in thread Thread-2:
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m   File "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py", line 68, in run
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m     item = self.task_q.get()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m            ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m   File "<string>", line 2, in get
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py", line 822, in _callmethod
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m     kind, result = conn.recv()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 250, in recv
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m     buf = self._recv_bytes()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m           ^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 430, in _recv_bytes
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m     buf = self._recv(4)
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m           ^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 399, in _recv
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m     raise EOFError
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP0 pid=11044)[0;0m EOFError
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m Exception in thread Thread-2:
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m   File "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py", line 68, in run
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m     item = self.task_q.get()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m            ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m   File "<string>", line 2, in get
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py", line 822, in _callmethod
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m     kind, result = conn.recv()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 250, in recv
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m     buf = self._recv_bytes()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m           ^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 430, in _recv_bytes
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m     buf = self._recv(4)
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m           ^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 399, in _recv
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m     raise EOFError
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP1 pid=11047)[0;0m EOFError
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m Exception in thread Thread-2:
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m Exception in thread Thread-2:
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m   File "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py", line 68, in run
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m   File "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py", line 68, in run
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m     item = self.task_q.get()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m            ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m     item = self.task_q.get()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m   File "<string>", line 2, in get
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py", line 822, in _callmethod
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m            ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m   File "<string>", line 2, in get
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py", line 822, in _callmethod
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m     kind, result = conn.recv()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 250, in recv
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m     buf = self._recv_bytes()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m     kind, result = conn.recv()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m           ^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 430, in _recv_bytes
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m     buf = self._recv(4)
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 250, in recv
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m           ^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 399, in _recv
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m     buf = self._recv_bytes()
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m     raise EOFError
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP2 pid=11052)[0;0m EOFError
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m           ^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 430, in _recv_bytes
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m     buf = self._recv(4)
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m           ^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 399, in _recv
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m     raise EOFError
[1;36m(EngineCore_DP0 pid=11037)[0;0m [1;36m(Worker_TP3 pid=11057)[0;0m EOFError
